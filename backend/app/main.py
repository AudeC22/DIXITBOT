#==============================================
# Utile pour le scrapping --> appel du script
#==============================================
from fastapi import FastAPI  # # ğŸš€ FastAPI
from pydantic import BaseModel  # # ğŸ§¾ Validation payload
from scraping.scrapping import scrape_arxiv_cs  # # ğŸ•·ï¸ Import de ton scraper

app = FastAPI()  # # ğŸ§  API

class ArxivScrapeRequest(BaseModel):  # # ğŸ§¾ SchÃ©ma de requÃªte
    query: str  # # ğŸ” Mots-clÃ©s
    max_results: int = 50  # # ğŸ¯ Limite (capÃ©e Ã  100)
    sort: str = "relevance"  # # ğŸ§­ relevance | submitted_date | last_updated_date
    subcategory: str | None = None  # # ğŸ§© Ex cs.LG

@app.post("/scrape/arxiv")  # # ğŸ›£ï¸ Endpoint demandÃ©
def scrape_arxiv(req: ArxivScrapeRequest):  # # ğŸ¯ Handler
    try:  # # ğŸ§¯ Protection
        return scrape_arxiv_cs(  # # ğŸš€ Appel scraper
            query=req.query,  # # ğŸ”
            max_results=req.max_results,  # # ğŸ¯
            sort=req.sort,  # # ğŸ§­
            subcategory=req.subcategory,  # # ğŸ§©
            polite_min_s=1.5,  # # ğŸ˜‡
            polite_max_s=2.0,  # # ğŸ˜‡
            data_lake_raw_dir="data_lake/raw",  # # ğŸ’¾
        )  # # âœ… Fin appel
    except Exception as e:  # # âŒ Si crash
        return {"ok": False, "error": str(e)}  # # ğŸ§¾ Erreur structurÃ©e
#==============================================
# End util pour le script scrapping
#==============================================