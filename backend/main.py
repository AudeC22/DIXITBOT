#==============================================
# Utile pour le scrapping + QA --> appel du scraper + appel Ollama (Qwen3)
#==============================================

# üöÄ FastAPI
from fastapi import FastAPI  # # Framework API # #
from pydantic import BaseModel  # # Validation payload # #

# üåê HTTP client (API REST Ollama)
import requests  # # Appels HTTP vers Ollama # #

# üßπ Nettoyage texte
import re  # # Regex pour normaliser espaces # #

# üï∑Ô∏è Import du scraper SCOPED (cibl√© th√©matique)
from module_MCP_scraping.scrapping import scrape_arxiv_cs_scoped  # # ‚úÖ IMPORTANT: version "scoped" # #

app = FastAPI()  # # üß† API

#==============================================
# 0) Healthcheck
#==============================================

@app.get("/health")  # # ‚úÖ V√©rifier que l'API tourne
def health():  # # Handler
    return {"ok": True}  # # R√©ponse simple

#==============================================
# 1) Endpoint : Scrape arXiv (SCOPED)
#==============================================

class ArxivScrapeRequest(BaseModel):  # # üßæ Sch√©ma de requ√™te
    query: str  # # üîé Mots-cl√©s utilisateur
    theme: str | None = None  # # üéØ ai_ml|algo_ds|net_sys|cyber_crypto|pl_se|hci_data
    max_results: int = 20  # # üéØ Limite (cap√©e √† 100)
    sort: str = "relevance"  # # üß≠ relevance | submitted_date
    debug_max_chars: int = 50000  # # üß™ debug HTML coup√©

@app.post("/scrape/arxiv")  # # üõ£Ô∏è Endpoint scrapping
def scrape_arxiv(req: ArxivScrapeRequest):  # # üéØ Handler
    try:
        return scrape_arxiv_cs_scoped(
            user_query=req.query,
            theme=req.theme,
            max_results=req.max_results,
            sort=req.sort,
            data_lake_raw_dir="data_lake/raw/cache",  # # üíæ √©crit dans le projet
            enrich_abs=True,
            enable_post_filter=True,
            debug_max_chars=req.debug_max_chars,
        )
    except Exception as e:
        return {"ok": False, "error": str(e)}

#==============================================
# 2) Endpoint : Question -> Scraping -> Qwen3 -> R√©ponse
#==============================================

class AskRequest(BaseModel):  # # üßæ Requ√™te QA
    question: str  # # ‚ùì Question utilisateur
    theme: str | None = "ai_ml"  # # üéØ Par d√©faut IA/ML (modifiable)
    max_results: int = 3  # # üéØ Nb papiers
    sort: str = "relevance"  # # üß≠ Tri
    model: str = "qwen3:1.7b"  # # ü§ñ Mod√®le Ollama
    debug: bool = False  # # üß™ Si True, renvoie aussi infos debug (paths, HTTP, etc.)

def _clean(s: str) -> str:  # # üßπ Nettoyage
    s = (s or "").strip()
    s = re.sub(r"\s+", " ", s)
    return s

def _build_context(items: list, max_chars: int = 14000) -> str:  # # üßæ Contexte compact
    chunks = []
    total = 0
    for i, it in enumerate(items, start=1):
        block = (
            f"[PAPER {i}]\n"
            f"arxiv_id: {_clean(it.get('arxiv_id',''))}\n"
            f"title: {_clean(it.get('title',''))}\n"
            f"submitted_date: {_clean(it.get('submitted_date',''))}\n"
            f"abs_url: {_clean(it.get('abs_url',''))}\n"
            f"pdf_url: {_clean(it.get('pdf_url',''))}\n"
            f"doi: {_clean(it.get('doi',''))}\n"
            f"abstract: {_clean(it.get('abstract',''))}\n"
        )
        if total + len(block) > max_chars:
            break
        chunks.append(block)
        total += len(block)
    return "\n".join(chunks)

def _ollama_generate(prompt: str, model: str) -> str:  # # üîå Appel Ollama
    url = "http://localhost:11434/api/generate"
    payload = {
        "model": model,
        "prompt": prompt,
        "stream": False,
    }
    r = requests.post(url, json=payload, timeout=300)
    r.raise_for_status()
    data = r.json()
    return (data.get("response") or "").strip()

@app.post("/ask")  # # üõ£Ô∏è Endpoint QA
def ask(req: AskRequest):  # # üéØ Handler QA
    try:
        question = _clean(req.question)
        if not question:
            return {"ok": False, "error": "Question vide."}

        # 1) Scraping cibl√© (SCOPED)
        results = scrape_arxiv_cs_scoped(
            user_query=question,
            theme=req.theme,
            max_results=req.max_results,
            sort=req.sort,
            data_lake_raw_dir="data_lake/raw/cache",
            enrich_abs=True,
            enable_post_filter=True,
            debug_max_chars=50000,
        )

        items = results.get("items") or []
        if not items:
            # ‚úÖ On renvoie aussi saved_to/bundle pour diagnostiquer facilement
            out = {
                "ok": True,
                "question": question,
                "answer": "Aucun papier trouv√© (ou parsing impossible). Regarde le bundle HTML et last_search_http.",
                "count": 0,
            }
            if req.debug:
                out["debug"] = {
                    "saved_to": results.get("saved_to"),
                    "bundle_html_file": results.get("bundle_html_file"),
                    "last_search_http": results.get("last_search_http"),
                    "last_search_url": results.get("last_search_url"),
                    "raw_cache_dir": results.get("raw_cache_dir"),
                }
            return out

        # 2) Contexte compact
        context = _build_context(items, max_chars=14000)

        # 3) Prompt strict (anti-hallucination)
        prompt = (
            "Tu es un assistant de recherche.\n"
            "Tu dois r√©pondre UNIQUEMENT √† partir du CONTEXTE fourni.\n"
            "Si une info n'est pas dans le contexte, dis: \"Je ne peux pas l'affirmer avec ce contexte\".\n"
            "\n"
            "Format demand√©:\n"
            "1) R√©ponse courte (3-6 lignes)\n"
            "2) Points cl√©s (5 bullets)\n"
            "3) Papiers cit√©s (liste: arxiv_id + title)\n"
            "\n"
            f"QUESTION:\n{question}\n\n"
            f"CONTEXTE:\n{context}\n"
        )

        # 4) Appel Qwen3 via Ollama
        answer = _ollama_generate(prompt=prompt, model=req.model)

        # 5) Items minimalistes
        items_min = [
            {"arxiv_id": it.get("arxiv_id", ""), "title": it.get("title", ""), "abs_url": it.get("abs_url", "")}
            for it in items
        ]

        out = {
            "ok": True,
            "question": question,
            "theme": req.theme,
            "query_used": results.get("scoped_query"),
            "count": len(items_min),
            "answer": answer,
            "items": items_min,
        }

        if req.debug:
            out["debug"] = {
                "saved_to": results.get("saved_to"),
                "bundle_html_file": results.get("bundle_html_file"),
                "last_search_http": results.get("last_search_http"),
                "last_search_url": results.get("last_search_url"),
                "raw_cache_dir": results.get("raw_cache_dir"),
            }

        return out

    except Exception as e:
        return {"ok": False, "error": str(e)}
