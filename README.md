# DIXITBOT
Cr√©ation d'un chat IA BOT dans le cadre d'un Projet Epitech Groupe 34 

# ü§ñ DIXITBOT ‚Äî Agent conversationnel intelligent

Ce projet est un **agent conversationnel intelligent** d√©velopp√© dans le cadre du projet IA BOT.
Il repose sur une architecture en **4 couches** :
- Frontend (web app)
- Backend Python (API REST)
- Serveur MCP (tooling)
- Mod√®le IA local (Ollama)

---

## üß± Architecture (vue d‚Äôensemble)

- **Frontend** : HTML / CSS / JavaScript  
- **Backend** : Python + FastAPI  
- **IA locale** : Ollama + mod√®le `qwen2.5:1.5b`  
- **Tooling** : 
Module : scraping de donn√©es publiques (site cell.com)  
    _ Le JSON = ton r√©sultat structur√© final (ce que tu veux exploiter).
    _ Le HTML = une copie brute du GET (preuve + debug).
        √áa sert √† :
        v√©rifier que le scraping a bien r√©cup√©r√© la bonne page
        comprendre pourquoi un champ manque (s√©lecteur faux, page diff√©rente, etc.)
        garder une trace reproductible (consigne prof souvent appr√©ci√©e)

Module Email :  Installer MailHog sur Windows
Option 1 : Installation simple (recommand√©)

T√©l√©chargez MailHog pour Windows : Mailhog 1.0.1 : MailHog_windows_amd64.exe

Allez sur : https://github.com/mailhog/MailHog/releases
T√©l√©chargez MailHog_windows_amd64.exe

- **Communication** : API REST  

## Flux agentique

1. L‚Äôutilisateur envoie une requ√™te via l‚Äôinterface web
2. Le backend analyse l‚Äôintention
3. La m√©moire et la knowledge base sont consult√©es
4. Si l‚Äôinformation est insuffisante, un tool MCP est d√©clench√©
5. Le tool effectue un scraping cibl√©
6. Les donn√©es sont analys√©es par le mod√®le IA local (Ollama)
7. Une r√©ponse contextualis√©e est retourn√©e √† l‚Äôutilisateur

## ‚öôÔ∏è Installation (environnement local)

### 1Ô∏è‚É£ Pr√©requis

- Windows 10 ou 11  
- Python 3.10 ou plus  
- Git  
- Connexion Internet (pour le scraping et le t√©l√©chargement du mod√®le)

---

### 2Ô∏è‚É£ Installer Ollama (obligatoire)

Ollama est utilis√© pour ex√©cuter un **mod√®le de langage open-source en local**.

üëâ T√©l√©charger et installer Ollama pour Windows :  
https://ollama.com/download/windows

Apr√®s installation, red√©marrer VS Code ou le terminal, puis v√©rifier :

```bash
ollama --version


