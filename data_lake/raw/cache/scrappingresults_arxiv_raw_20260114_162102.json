{
  "ok": true,
  "query": "multimodal transformer misogyny detection",
  "sort": "relevance",
  "count": 1,
  "max_results": 3,
  "hit_limit_100": false,
  "message_if_limit": "",
  "items": [
    {
      "arxiv_id": "2601.08457",
      "title": "An Under-Explored Application for Explainable Multimodal Misogyny Detection in code-mixed Hindi-English",
      "authors": [
        "Sargam Yadav",
        "Abhishek Kaushik",
        "Kevin Mc Daid"
      ],
      "abstract": "Digital platforms have an ever-expanding user base, and act as a hub for communication, business, and connectivity. However, this has also allowed for the spread of hate speech and misogyny . Artificial intelligence models have emerged as an effective solution for countering online hate speech but are under explored for low resource and code-mixed languages and suffer from a lack of interpretability. Explainable Artificial Intelligence (XAI) can enhance transparency in the decisions of deep learning models, which is crucial for a sensitive domain such as hate speech detection . In this paper, we present a multi-modal and explainable web application for detecting misogyny in text and memes in code-mixed Hindi and English. The system leverages state-of-the-art transformer -based models that support multilingual and multimodal settings. For text-based misogyny identification, the system utilizes XLM-RoBERTa (XLM-R) and multilingual Bidirectional Encoder Representations from Transformers (mBERT) on a dataset of approximately 4,193 comments. For multimodal misogyny identification from memes, the system utilizes mBERT + EfficientNet, and mBERT + ResNET trained on a dataset of approximately 4,218 memes. It also provides feature importance scores using explainability techniques including Shapley Additive Values (SHAP) and Local Interpretable Model Agnostic Explanations (LIME). The application aims to serve as a tool for both researchers and content moderators, to promote further research in the field, combat gender based digital violence, and ensure a safe digital space. The system has been evaluated using human evaluators who provided their responses on Chatbot Usability Questionnaire (CUQ) and User Experience Questionnaire (UEQ) to determine overall usability.",
      "submitted_date": "13 January, 2026",
      "abs_url": "https://arxiv.org/abs/2601.08457",
      "pdf_url": "https://arxiv.org/pdf/2601.08457",
      "doi": "",
      "versions": [],
      "last_updated_raw": "",
      "html_url": "https://arxiv.org/html/2601.08457",
      "published_date": "",
      "license": "",
      "sections": [],
      "content_text": "",
      "references": [],
      "references_dois": [],
      "fallback_urls": [
        "https://arxiv.org/html/2601.08457"
      ],
      "errors": [
        "html_http_404"
      ],
      "missing_fields": [
        "doi",
        "versions",
        "last_updated_raw",
        "published_date",
        "license",
        "sections",
        "content_text",
        "references",
        "references_dois"
      ],
      "url_hint_if_missing": "Champs manquants: doi, versions, last_updated_raw, published_date, license, sections, content_text, references, references_dois. Tu peux verifier ici: abs=https://arxiv.org/abs/2601.08457 | html=https://arxiv.org/html/2601.08457 | pdf=https://arxiv.org/pdf/2601.08457"
    }
  ],
  "bundle_html_file": "data_lake/raw/cache\\scrappingresults_arxiv_bundle_20260114_162102.html",
  "supported_fields": [
    "arxiv_id",
    "title",
    "authors",
    "abstract",
    "submitted_date",
    "abs_url",
    "pdf_url",
    "doi",
    "versions",
    "last_updated_raw",
    "html_url",
    "published_date",
    "license",
    "sections",
    "content_text",
    "references",
    "references_dois"
  ]
}