# ============================================================  # # ğŸ“Œ DÃ©but du script
# ğŸ§­ Analyse dâ€™une page HTML arXiv (/html/xxxx) -> Sections -> Excel dans TÃ©lÃ©chargements  # # ğŸ¯ Objectif
# ============================================================  # # ğŸ“Œ SÃ©parateur visuel

import os  # # ğŸ“ GÃ©rer les chemins Windows
import re  # # ğŸ” Nettoyage/normalisation texte via regex
import json  # # ğŸ§¾ SÃ©rialiser des listes/dicts (content_elements) dans une cellule Excel
import datetime  # # ğŸ•’ Timestamp pour nommer les fichiers exportÃ©s
from pathlib import Path  # # ğŸ“‚ RÃ©cupÃ©rer le dossier TÃ©lÃ©chargements facilement
from typing import List, Dict, Any  # # ğŸ§© Typage pour clartÃ©

import requests  # # ğŸŒ TÃ©lÃ©charger le HTML via HTTP
import pandas as pd  # # ğŸ“Š Structurer les rÃ©sultats et exporter en Excel
from bs4 import BeautifulSoup, Tag  # # ğŸ² Parser HTML et manipuler des balises


# ============================================================  # # ğŸ“Œ SÃ©parateur
# ğŸŒ A) TÃ©lÃ©charger le HTML dâ€™une page  # # âœ… GET (requests)
# ============================================================  # # ğŸ“Œ SÃ©parateur

def fetch_html(url: str, timeout: int = 30) -> str:  # # ğŸŒ TÃ©lÃ©charge le HTML brut d'une URL
    headers = {  # # ğŸªª User-Agent pour Ã©viter certains blocages
        "User-Agent": (  # # ğŸ§¾ ChaÃ®ne UA complÃ¨te
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "  # # ğŸªŸ UA Windows
            "AppleWebKit/537.36 (KHTML, like Gecko) "  # # ğŸŒ Moteur
            "Chrome/120.0.0.0 Safari/537.36"  # # ğŸŒ Navigateur
        )
    }  # # âœ… Fin headers
    resp = requests.get(url, headers=headers, timeout=timeout)  # # âœ… RequÃªte GET
    resp.raise_for_status()  # # âŒ LÃ¨ve une erreur si HTTP != 200
    return resp.text  # # ğŸ“„ Retourne le HTML brut (string)


# ============================================================  # # ğŸ“Œ SÃ©parateur
# ğŸ§¼ B) Nettoyage texte  # # âœ… Uniformiser les espaces
# ============================================================  # # ğŸ“Œ SÃ©parateur

def clean_text(s: str) -> str:  # # ğŸ§¼ Nettoie le texte (espaces multiples, retours)
    if not s:  # # âœ… Si None ou chaÃ®ne vide
        return ""  # # âœ… Retourne vide
    s = re.sub(r"\s+", " ", s)  # # âœ… Remplace tout bloc d'espaces/retours par 1 espace
    return s.strip()  # # âœ… Supprime les espaces en dÃ©but/fin


# ============================================================  # # ğŸ“Œ SÃ©parateur
# ğŸ§­ C) Construire des sÃ©lecteurs (CSS + XPath)  # # âœ… Pour repÃ©rer oÃ¹ sont les infos
# ============================================================  # # ğŸ“Œ SÃ©parateur

def css_selector(el: Tag) -> str:  # # ğŸ§­ Construit un sÃ©lecteur CSS le plus stable possible
    if not isinstance(el, Tag):  # # âœ… SÃ©curitÃ© : doit Ãªtre une balise
        return ""  # # âœ… Sinon vide

    parts: List[str] = []  # # âœ… Morceaux de selector (de bas vers le haut)
    cur: Tag = el  # # âœ… Pointeur courant

    while cur and isinstance(cur, Tag) and cur.name != "[document]":  # # âœ… Remonte l'arbre DOM
        if cur.get("id"):  # # âœ… Si lâ€™Ã©lÃ©ment a un id
            parts.append(f"{cur.name}#{cur.get('id')}")  # # âœ… id = unique => ancrage fort
            break  # # âœ… On peut s'arrÃªter ici
        else:
            cls = cur.get("class", [])  # # âœ… Liste de classes
            cls = [c for c in cls if c and isinstance(c, str)]  # # âœ… Filtre sÃ©curitÃ©
            base = cur.name  # # âœ… Base = nom de balise

            if cls:  # # âœ… Si classes prÃ©sentes
                base += "." + ".".join(cls[:3])  # # âœ… Ajoute jusqu'Ã  3 classes (pas trop long)
            else:
                if cur.parent and isinstance(cur.parent, Tag):  # # âœ… Si parent valide
                    siblings_same = [sib for sib in cur.parent.find_all(cur.name, recursive=False)]  # # âœ… FrÃ¨res mÃªme tag
                    if len(siblings_same) > 1:  # # âœ… Si plusieurs frÃ¨res identiques
                        idx = siblings_same.index(cur) + 1  # # âœ… Index CSS nth-of-type commence Ã  1
                        base += f":nth-of-type({idx})"  # # âœ… Ajoute nth-of-type

            parts.append(base)  # # âœ… Ajoute ce niveau

        cur = cur.parent  # # âœ… Remonte dâ€™un niveau

    parts.reverse()  # # âœ… Reconstruit du haut vers le bas
    return " > ".join(parts)  # # âœ… Retourne le selector CSS final


def xpath_selector(el: Tag) -> str:  # # ğŸ§­ Construit un XPath lisible et stable
    if not isinstance(el, Tag):  # # âœ… SÃ©curitÃ© : doit Ãªtre une balise
        return ""  # # âœ… Sinon vide

    parts: List[str] = []  # # âœ… Morceaux XPath
    cur: Tag = el  # # âœ… Pointeur courant

    while cur and isinstance(cur, Tag) and cur.name != "[document]":  # # âœ… Remonte DOM
        if cur.get("id"):  # # âœ… Si id
            parts.append(f'//*[@id="{cur.get("id")}"]')  # # âœ… Ancrage par id
            break  # # âœ… Stop (id suffit)
        if cur.parent and isinstance(cur.parent, Tag):  # # âœ… Si parent valide
            same = [sib for sib in cur.parent.find_all(cur.name, recursive=False)]  # # âœ… FrÃ¨res mÃªme tag
            if len(same) > 1:  # # âœ… Si plusieurs
                idx = same.index(cur) + 1  # # âœ… Index XPath commence Ã  1
                parts.append(f"{cur.name}[{idx}]")  # # âœ… tag[n]
            else:
                parts.append(cur.name)  # # âœ… tag simple
        else:
            parts.append(cur.name)  # # âœ… tag simple (fallback)
        cur = cur.parent  # # âœ… Remonte

    parts.reverse()  # # âœ… Chemin racine -> feuille
    if parts and parts[0].startswith('//*[@id="'):  # # âœ… Si ancrage id
        return "/".join(parts)  # # âœ… XPath ancrÃ©
    return "/" + "/".join(parts)  # # âœ… XPath absolu


# ============================================================  # # ğŸ“Œ SÃ©parateur
# ğŸ·ï¸ D) DÃ©tecter un "titre" (heading)  # # âœ… h1..h6 + heuristiques
# ============================================================  # # ğŸ“Œ SÃ©parateur

def is_heading(el: Tag) -> bool:  # # ğŸ·ï¸ DÃ©termine si une balise est un titre de section
    if not isinstance(el, Tag):  # # âœ… SÃ©curitÃ©
        return False  # # âœ…

    if el.name in {"h1", "h2", "h3", "h4", "h5", "h6"}:  # # âœ… Titres HTML standards
        return True  # # âœ…

    role = (el.get("role") or "").strip().lower()  # # âœ… ARIA role Ã©ventuel
    if role == "heading":  # # âœ… Certains sites utilisent role=heading
        return True  # # âœ…

    classes = " ".join(el.get("class", [])).lower()  # # âœ… Classes concatÃ©nÃ©es
    if any(k in classes for k in ["title", "heading", "section-title", "ltx_title"]):  # # âœ… Heuristique (LaTeXML incluse)
        return bool(clean_text(el.get_text(" ", strip=True)))  # # âœ… Exige un texte non vide

    return False  # # âœ… Pas un titre


# ============================================================  # # ğŸ“Œ SÃ©parateur
# ğŸ“¦ E) RÃ©cupÃ©rer le contenu dâ€™une section (jusquâ€™au prochain titre)  # # âœ… parsing simple
# ============================================================  # # ğŸ“Œ SÃ©parateur

def collect_section_content(heading_el: Tag, max_chars: int = 6000) -> Dict[str, Any]:  # # ğŸ“¦ Contenu associÃ© Ã  un titre
    contents: List[str] = []  # # âœ… Stocke les blocs de texte
    content_elements: List[Dict[str, Any]] = []  # # âœ… Stocke les infos "oÃ¹ est le contenu" dans le DOM

    for sib in heading_el.next_siblings:  # # âœ… Parcourt les frÃ¨res suivants
        if isinstance(sib, Tag):  # # âœ… Ignore les strings/espaces
            if is_heading(sib):  # # âœ… Stop si prochain titre
                break  # # âœ… Fin de section

            if sib.name in {"p", "div", "ul", "ol", "table", "figure", "section"}:  # # âœ… Balises utiles
                txt = clean_text(sib.get_text(" ", strip=True))  # # âœ… Texte du bloc
                if txt:  # # âœ… Ignore vide
                    contents.append(txt)  # # âœ… Ajoute au contenu
                    content_elements.append({  # # âœ… Ajoute la localisation DOM
                        "content_tag": sib.name,  # # âœ… Balise
                        "content_id": sib.get("id", ""),  # # âœ… id
                        "content_class": " ".join(sib.get("class", [])),  # # âœ… classes
                        "content_css": css_selector(sib),  # # âœ… CSS selector
                        "content_xpath": xpath_selector(sib),  # # âœ… XPath
                    })  # # âœ… Fin dict

        if sum(len(c) for c in contents) > max_chars:  # # âœ… Coupe si trop long (Ã©vite sections Ã©normes)
            break  # # âœ… Stop

    section_text = clean_text(" ".join(contents))  # # âœ… ConcatÃ¨ne tout le texte de la section
    return {  # # âœ… Retour structurÃ©
        "section_text": section_text,  # # âœ… Texte complet section
        "content_elements": content_elements,  # # âœ… OÃ¹ se trouvent les blocs dans la page
    }  # # âœ… Fin return


# ============================================================  # # ğŸ“Œ SÃ©parateur
# ğŸ” F) Analyser une page et produire un DataFrame  # # âœ… 1 ligne = 1 titre + contenu
# ============================================================  # # ğŸ“Œ SÃ©parateur

def analyze_page(url: str) -> pd.DataFrame:  # # ğŸ” Analyse une page et retourne un DataFrame
    html = fetch_html(url)  # # âœ… GET : tÃ©lÃ©charger le HTML
    soup = BeautifulSoup(html, "lxml")  # # âœ… Parse HTML avec lxml

    main = soup.find("main")  # # âœ… Essaie de cibler <main>
    root = main if main else soup.body if soup.body else soup  # # âœ… Fallback si <main> absent

    headings: List[Tag] = []  # # âœ… Liste des titres
    for el in root.find_all(True):  # # âœ… Parcourt toutes les balises
        if is_heading(el):  # # âœ… Filtre titres
            title_text = clean_text(el.get_text(" ", strip=True))  # # âœ… Texte titre
            if title_text:  # # âœ… Ignore vides
                headings.append(el)  # # âœ… Ajoute

    rows: List[Dict[str, Any]] = []  # # âœ… Lignes du futur Excel
    for i, h in enumerate(headings, start=1):  # # âœ… Pour chaque titre
        title_text = clean_text(h.get_text(" ", strip=True))  # # âœ… Texte du titre
        level = h.name if h.name in {"h1", "h2", "h3", "h4", "h5", "h6"} else "custom"  # # âœ… Niveau

        content_pack = collect_section_content(h)  # # âœ… RÃ©cupÃ¨re le contenu jusquâ€™au prochain titre

        if not content_pack.get("section_text"):  # # âœ… Si contenu vide
            continue  # # âœ… On saute (Ã©vite lignes inutiles)

        rows.append({  # # âœ… Ajoute une ligne
            "url": url,  # # âœ… URL analysÃ©e
            "heading_index": i,  # # âœ… Rang du titre
            "heading_level": level,  # # âœ… h1/h2/â€¦ ou custom
            "heading_text": title_text,  # # âœ… Texte du titre
            "heading_tag": h.name if hasattr(h, "name") else "",  # # âœ… Nom balise
            "heading_id": h.get("id", ""),  # # âœ… id
            "heading_class": " ".join(h.get("class", [])),  # # âœ… classes
            "heading_css": css_selector(h),  # # âœ… CSS selector du titre
            "heading_xpath": xpath_selector(h),  # # âœ… XPath du titre
            "section_text": content_pack.get("section_text", ""),  # # âœ… Texte de la section
            "content_elements": json.dumps(content_pack.get("content_elements", []), ensure_ascii=False),  # # âœ… JSON des blocs
        })  # # âœ… Fin dict

    df = pd.DataFrame(rows)  # # âœ… Convertit en DataFrame
    return df  # # âœ… Retour


# ============================================================  # # ğŸ“Œ SÃ©parateur
# ğŸ’¾ G) Export Excel dans TÃ©lÃ©chargements  # # âœ… C:\Users\<toi>\Downloads
# ============================================================  # # ğŸ“Œ SÃ©parateur

def export_to_downloads_excel(df: pd.DataFrame, filename_prefix: str = "page_analysis") -> str:  # # ğŸ’¾ Exporte le DataFrame en xlsx
    downloads_dir = str(Path.home() / "Downloads")  # # âœ… Dossier TÃ©lÃ©chargements Windows
    ts = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")  # # âœ… Timestamp pour nom unique
    out_path = os.path.join(downloads_dir, f"{filename_prefix}_{ts}.xlsx")  # # âœ… Chemin complet final
    df.to_excel(out_path, index=False)  # # âœ… Ã‰crit l'Excel sans index
    return out_path  # # âœ… Retourne le chemin du fichier crÃ©Ã©


# ============================================================  # # ğŸ“Œ SÃ©parateur
# ğŸ§ª H) Test local (Ã  lancer en direct)  # # âœ… python researchlementspages.py
# ============================================================  # # ğŸ“Œ SÃ©parateur

if __name__ == "__main__":  # # â–¶ï¸ ExÃ©cution directe uniquement
    test_url = "https://arxiv.org/html/2601.07830v1"  # # ğŸ”— Mets ici lâ€™URL que tu veux analyser
    df = analyze_page(test_url)  # # âœ… Analyse la page
    out = export_to_downloads_excel(df, filename_prefix="arxiv_html_sections")  # # âœ… Export Excel
    print(f"âœ… Excel crÃ©Ã© dans TÃ©lÃ©chargements : {out}")  # # ğŸ–¨ï¸ Affiche le chemin
