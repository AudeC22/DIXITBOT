# ðŸ“š Importation des bibliothÃ¨ques
import re  # # âœ… Pour nettoyer/normaliser du texte via regex
import requests  # # âœ… Pour tÃ©lÃ©charger le HTML d'une page web via HTTP
import pandas as pd  # # âœ… Pour structurer les rÃ©sultats et exporter en Excel
from bs4 import BeautifulSoup, Tag  # # âœ… Pour parser le HTML et manipuler les balises

# ðŸŒ TÃ©lÃ©chargement HTML
def fetch_html(url: str, timeout: int = 30) -> str:
    # âœ… TÃ©lÃ©charge le HTML brut d'une page web (URL) et renvoie le texte HTML
    headers = {  # # âœ… En-tÃªtes HTTP pour Ã©viter certains blocages (user-agent)
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 "
                      "(KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
    }
    resp = requests.get(url, headers=headers, timeout=timeout)  # # âœ… RequÃªte GET
    resp.raise_for_status()  # # âœ… Stoppe avec une erreur si HTTP != 200
    return resp.text  # # âœ… Retourne le HTML

# ðŸ§¼ Nettoyage texte
def clean_text(s: str) -> str:
    # âœ… Nettoie un texte : supprime espaces multiples et retours Ã  la ligne inutiles
    if not s:  # # âœ… Si chaÃ®ne vide ou None
        return ""  # # âœ… Renvoie vide
    s = re.sub(r"\s+", " ", s)  # # âœ… Remplace toute suite d'espaces/retours par 1 espace
    return s.strip()  # # âœ… Supprime espaces dÃ©but/fin

# ðŸ§­ Construire un CSS selector robuste
def css_selector(el: Tag) -> str:
    # âœ… Construit un sÃ©lecteur CSS "le plus prÃ©cis possible"
    # âœ… PrioritÃ© : id (unique) > tag + classes > tag + nth-of-type
    if not isinstance(el, Tag):  # # âœ… VÃ©rifie que c'est une balise
        return ""  # # âœ… Sinon renvoie vide

    parts = []  # # âœ… Liste des morceaux du selector (du bas vers le haut)
    cur = el  # # âœ… On part de l'Ã©lÃ©ment ciblÃ©

    while cur and isinstance(cur, Tag) and cur.name != "[document]":  # # âœ… Remonte l'arbre DOM
        if cur.get("id"):  # # âœ… Si l'Ã©lÃ©ment a un id
            parts.append(f'{cur.name}#{cur.get("id")}')  # # âœ… id = unique => on peut s'arrÃªter
            break  # # âœ… Stoppe la remontÃ©e
        else:
            cls = cur.get("class", [])  # # âœ… RÃ©cupÃ¨re la liste de classes
            cls = [c for c in cls if c and isinstance(c, str)]  # # âœ… Filtre sÃ©curitÃ©
            base = cur.name  # # âœ… Base du sÃ©lecteur = nom de balise
            if cls:  # # âœ… Si classes prÃ©sentes
                base += "." + ".".join(cls[:3])  # # âœ… Ajoute jusqu'Ã  3 classes (Ã©vite selectors Ã©normes)
            else:
                # âœ… Pas de classes : on ajoute un nth-of-type pour Ãªtre stable dans le parent
                if cur.parent and isinstance(cur.parent, Tag):  # # âœ… VÃ©rifie parent
                    siblings_same_tag = [sib for sib in cur.parent.find_all(cur.name, recursive=False)]  # # âœ… FrÃ¨res mÃªme tag
                    if len(siblings_same_tag) > 1:  # # âœ… Si plusieurs frÃ¨res identiques
                        idx = siblings_same_tag.index(cur) + 1  # # âœ… nth-of-type commence Ã  1
                        base += f":nth-of-type({idx})"  # # âœ… Ajoute nth-of-type
            parts.append(base)  # # âœ… Ajoute ce niveau au selector

        cur = cur.parent  # # âœ… Remonte d'un niveau

    parts.reverse()  # # âœ… On a construit du bas vers le haut, on inverse
    return " > ".join(parts)  # # âœ… CSS final

# ðŸ§­ Construire un XPath simple (lisible)
def xpath_selector(el: Tag) -> str:
    # âœ… Construit un XPath simple : /html/body/.../tag[n]
    if not isinstance(el, Tag):  # # âœ… VÃ©rifie que c'est une balise
        return ""  # # âœ… Sinon vide

    parts = []  # # âœ… Morceaux XPath
    cur = el  # # âœ… Point de dÃ©part

    while cur and isinstance(cur, Tag) and cur.name != "[document]":  # # âœ… Remonte DOM
        if cur.get("id"):  # # âœ… Si id, on ancre ici (plus stable)
            parts.append(f'//*[@id="{cur.get("id")}"]')  # # âœ… XPath par id
            break  # # âœ… Stop
        if cur.parent and isinstance(cur.parent, Tag):  # # âœ… Si parent valide
            same = [sib for sib in cur.parent.find_all(cur.name, recursive=False)]  # # âœ… FrÃ¨res mÃªme tag
            if len(same) > 1:  # # âœ… Si plusieurs, on met l'index
                idx = same.index(cur) + 1  # # âœ… Index XPath commence Ã  1
                parts.append(f"{cur.name}[{idx}]")  # # âœ… tag + [n]
            else:
                parts.append(cur.name)  # # âœ… tag seul
        else:
            parts.append(cur.name)  # # âœ… tag seul
        cur = cur.parent  # # âœ… Remonte

    parts.reverse()  # # âœ… Inverse pour obtenir chemin racine -> feuille
    if parts and parts[0].startswith('//*[@id="'):  # # âœ… Si ancrÃ© par id
        return "/".join(parts)  # # âœ… XPath ancrÃ©
    return "/" + "/".join(parts)  # # âœ… XPath absolu

# ðŸ·ï¸ DÃ©tecter si une balise est un "titre"
def is_heading(el: Tag) -> bool:
    # âœ… DÃ©termine si la balise est un titre : h1..h6 ou role="heading" ou classes typiques "title"
    if not isinstance(el, Tag):  # # âœ… SÃ©curitÃ©
        return False  # # âœ…
    if el.name in {"h1", "h2", "h3", "h4", "h5", "h6"}:  # # âœ… Standard HTML
        return True  # # âœ…
    role = (el.get("role") or "").strip().lower()  # # âœ… Attribut ARIA role
    if role == "heading":  # # âœ… Certains sites utilisent div/span role=heading
        return True  # # âœ…
    classes = " ".join(el.get("class", [])).lower()  # # âœ… Classes en texte
    if any(k in classes for k in ["title", "heading", "section-title", "ltx_title"]):  # # âœ… Heuristique (inclut LaTeXML)
        # âš ï¸ On reste prudent : on exige aussi un texte non vide
        return bool(clean_text(el.get_text(" ", strip=True)))  # # âœ…
    return False  # # âœ…

# ðŸ“¦ Collecter le contenu associÃ© Ã  un titre (jusqu'au prochain titre)
def collect_section_content(heading_el: Tag, max_chars: int = 6000) -> dict:
    # âœ… RÃ©cupÃ¨re les Ã©lÃ©ments "contenu" aprÃ¨s le titre, jusqu'au prochain titre
    contents = []  # # âœ… Stocke des blocs de contenu texte
    content_elements = []  # # âœ… Stocke des infos d'Ã©lÃ©ments (tag + selectors)

    # âœ… On parcourt les "next siblings" (frÃ¨res suivants dans le DOM)
    for sib in heading_el.next_siblings:
        if isinstance(sib, Tag):  # # âœ… Ignore les strings/espaces
            if is_heading(sib):  # # âœ… Stop si on tombe sur le prochain titre
                break  # # âœ… Fin de section

            # âœ… On garde les blocs de contenu utiles (p, ul, ol, table, figure, div para, etc.)
            if sib.name in {"p", "div", "ul", "ol", "table", "figure", "section"}:
                txt = clean_text(sib.get_text(" ", strip=True))  # # âœ… Texte du bloc
                if txt:  # # âœ… Ignore vide
                    contents.append(txt)  # # âœ… Ajoute au contenu section
                    content_elements.append({  # # âœ… Ajoute la localisation exacte du bloc
                        "content_tag": sib.name,
                        "content_id": sib.get("id", ""),
                        "content_class": " ".join(sib.get("class", [])),
                        "content_css": css_selector(sib),
                        "content_xpath": xpath_selector(sib),
                    })

        # âœ… Coupe si on dÃ©passe max_chars (Ã©vite sections Ã©normes genre references)
        if sum(len(c) for c in contents) > max_chars:  # # âœ… Condition limite
            break  # # âœ…

    section_text = clean_text(" ".join(contents))  # # âœ… ConcatÃ¨ne le texte section
    return {  # # âœ… Retourne contenu + dÃ©tails
        "section_text": section_text,
        "content_elements": content_elements,
    }

# ðŸ”Ž Analyse d'une page
def analyze_page(url: str) -> pd.DataFrame:
    # âœ… Analyse une page et produit un DataFrame : 1 ligne par titre + contenu associÃ©
    html = fetch_html(url)  # # âœ… TÃ©lÃ©charge le HTML
    soup = BeautifulSoup(html, "lxml")  # # âœ… Parse le HTML avec lxml (plus robuste)

    # âœ… On cible le contenu principal si possible (sinon toute la page)
    main = soup.find("main")  # # âœ… Beaucoup de sites structurent via <main>
    root = main if main else soup.body if soup.body else soup  # # âœ… Fallback

    headings = []  # # âœ… Liste des titres trouvÃ©s
    for el in root.find_all(True):  # # âœ… Parcours toutes les balises
        if is_heading(el):  # # âœ… Filtre titres
            title_text = clean_text(el.get_text(" ", strip=True))  # # âœ… Texte du titre
            if title_text:  # # âœ… Ignore titres vides
                headings.append(el)  # # âœ… Ajoute

    rows = []  # # âœ… Lignes Excel
    for i, h in enumerate(headings, start=1):  # # âœ… Boucle titres
        title_text = clean_text(h.get_text(" ", strip=True))  # # âœ… Texte titre
        level = h.name if h.name in {"h1","h2","h3","h4","h5","h6"} else "custom"  # # âœ… Niveau
        content_pack = collect_section_content(h)  # # âœ… RÃ©cup contenu jusqu'au prochain titre

        # âœ… Si
